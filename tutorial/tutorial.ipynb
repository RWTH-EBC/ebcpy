{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on ebcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the following situation.\n",
    "From an experiment we have gathered following data:\n",
    "<img src=\"data/measured_data.png\">\n",
    "We want to use the data as an input to a simulation. However, as visible, the data is noisy and thus may lead to instability of our simulation.\n",
    "\n",
    "First we will load modules supporting this tutorial. Note that you should install matplotlib first if not already happenend, as only this tutorial needs matplotlib. For usage of ebcpy, you don't need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types\n",
    "Let's specify the path to our measurement data and load it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ebcpy import data_types\n",
    "# Specify the path to the measured data:\n",
    "path = os.path.join(os.getcwd(), \"data\", \"measuredData.csv\")\n",
    "tsd = data_types.TimeSeriesData(path, key=\"test\")\n",
    "print(tsd)\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.title(\"1: Measured data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "If you're familiar with `python` and `DataFrames`, you will ask  yourself: **Why do I need the TimeSeriesData-Class?** We implemented this class to combine the powerful `pandas.DataFrame` class with new functions for an easy usage in the context of Building Energy Systems for three main reasons:\n",
    "- Most data in our case is Time-Dependent, therefore functions for easy conversion between seconds (for Simulation) and Timestamps (for measurements) is needed\n",
    "- Most data is stored in files. Typically .hdf and .mat is used, .csv and even .xlsx files occur frequently. Pandas has different functions (`from_hdf`, `from_csv`) and no at all function for loading Modelica-Result files.\n",
    "- Working with energy related data, you most likely are interested in understanding where a value comes from. For this reason we base the TimeSeriesData-Class on the pandas MultiColumn-Feature. Every variable (e.g. Temperature) will get tags for specific reasons. The default being \"raw\", assuming that data loaded from a file without tags most likely is unprocessed.\n",
    "\n",
    "Note how the loaded measurement got the tag 'raw'. Else not much new, just DataFrame. Let's adjust the noisy data for the usage in a simulation tool like Modelica.\n",
    "\n",
    "For this reason, we load the preprocessing module of `ebcpy`. \n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "We want to manipulate only the values in the DataFrame.\n",
    "The easiest way to use the processing functions is to call the TimeSeriesData functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd.low_pass_filter(crit_freq=0.01, filter_order=2, variable=\"measured_T\", tag=\"raw\", new_tag=\"lowPass\")\n",
    "tsd.moving_average(window=10, variable=\"measured_T\", tag=\"raw\", new_tag=\"movingAverage\")\n",
    "# Plot the values\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.legend(tsd[\"measured_T\"].columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative is to call the preprocessing module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ebcpy import preprocessing\n",
    "# Extract the column of interest to get the trajectory or array for processing\n",
    "trajectory = tsd.get_columns_by_tag(\"raw\", variables=[\"measured_T\"], return_type=\"numpy\")\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can apply either a filter or a moving-average. To further understand differences between both options, adjust the parameters in the box below and rerun the cell. You will see how the output changes. Which function you use for your data is up to you, a general appraisal cannot be made.\n",
    "\n",
    "**Note**: The syntax for values for an existing variable with a new tag, you have to call:\n",
    "```python\n",
    "tsd.loc[:, (VARIABLE_NAME, NEW_TAG_NAME)] = VALUES\n",
    "```\n",
    "In this case: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsd.loc[:, (\"measured_T\", \"low_pass_filter\")] = preprocessing.low_pass_filter(\n",
    "    data=trajectory, \n",
    "    crit_freq=0.01, \n",
    "    filter_order=2)\n",
    "tsd.loc[:, (\"measured_T\", \"moving_average\")] = preprocessing.moving_average(\n",
    "    data=trajectory, \n",
    "    window=10)\n",
    "# Plot the values\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.legend(tsd[\"measured_T\"].columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assume we want to know when to turn on a certain device based on our measurements. Looking at our data, we know some device turned on or off, if the temperature rises above some 34 Â°C. To reproduce the signal for our simulation, we can use the `create_on_off_signal` method. For this example we use the default tag \"raw\", however you may also try \"moving_average\" or other created tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "tsd = preprocessing.create_on_off_signal(df=tsd,\n",
    "                                         col_names=[\"measured_T\"],\n",
    "                                         threshold= 307,\n",
    "                                         col_names_new=[\"Device_Input\"],\n",
    "                                         tags=[\"raw\"],\n",
    "                                         new_tag=\"converted_signal\")\n",
    "plt.plot(tsd[\"Device_Input\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are satisfied with our results, we may want to save our process in a file. For this case, the `TimeSeriesData`-Class holds a `save`-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(os.getcwd(), \"data\", \"measuredData_preprocessed.csv\")\n",
    "tsd.save(save_path, key=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data again and check if everything was correctly saved and the load-function also works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "tsd = data_types.TimeSeriesData(save_path, key=\"test\")\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.legend(tsd[\"measured_T\"].columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a closer look at the DataFrame-Object.\n",
    "\n",
    "We now have two variables, the measured temperature and the created signal. Furthermore we created new tags, allowing us to always recap where our data came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the measurement was made for 1 hour with a 1 second interval. Let's assume you want to run the simulation with a bigger time-interval. To not only use the data, but at a later stage also compare results, the `preprocessing` module holds a function for you.\n",
    "`clean_and_space_equally_time_series` Takes your data and resamples it to the desired frequency. Try different inputs, like \"1s\", \"30s\", \"2min\", \"1h\" or others.\n",
    "\n",
    "- Be aware that **upsampling** your data is to create artificial values. In contrast, **downsampling** is a valid and secure method.\n",
    "- See [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases) for allowed frequencies like \"15min\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd.clean_and_space_equally(desired_freq=\"1min\")\n",
    "tsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion\n",
    "\n",
    "Now let's get to the simulation part. If you are familiar with **Modelica**, you know *inputs from files* may either be in `.txt` or `.mat` format. Both options are supported in `ebcpy`.\n",
    "\n",
    "Let's take our preprocessed data and convert it to first to .txt, then to .mat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebcpy.utils import conversion\n",
    "from ebcpy import TimeSeriesData\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), \"data\", \"measuredData_preprocessed.hdf\")\n",
    "\n",
    "tsd = TimeSeriesData(file_path, key=\"test\")\n",
    "\n",
    "save_path_txt = conversion.convert_tsd_to_modelica_txt(\n",
    "    tsd=tsd,\n",
    "    save_path_file=os.path.join(os.getcwd(), \"data\", \"measuredData_preprocessed.txt\"),\n",
    "    table_name=\"Simulation_Input\",\n",
    "    # = [], = [(\"measured_T\", \"moving_average\")] o.s. is also possible.\n",
    "    columns=[\"Device_Input\"],\n",
    "    # Rerun the cell and change values \n",
    "    # below to understand these args.\n",
    "    offset=0, \n",
    "    sep=\"\\t\")\n",
    "\n",
    "# Let's print the first 15 lines to understand the result. \n",
    "# Simulation_Input is the table_name. \n",
    "# The tag is added to the varialbe\n",
    "print(\"\".join(open(save_path_txt, \"r\").readlines()[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion.convert_tsd_to_modelica_mat(\n",
    "    tsd=tsd,\n",
    "    save_path_file=os.path.join(os.getcwd(), \"data\", \"measuredData_preprocessed.mat\"),\n",
    "    columns=[(\"measured_T\", \"moving_average\")],\n",
    "    offset=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dymola API\n",
    "\n",
    "Now we will run a simulation using the `DymolaAPI`-Class. Make sure you have **Dymola** with a valid **license** installed on your machine to get this to run.\n",
    "\n",
    "If you are new to the research at the EBC-Institute, the [**AixLib**](https://github.com/RWTH-EBC/AixLib) is a good  starting point for modelling. Most systems with regard to building energy systems have been already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebcpy.simulationapi import dymola_api\n",
    "test_package = os.path.join(os.getcwd(), \"Modelica\", \"TestModel.mo\")\n",
    "\n",
    "DYM_API = dymola_api.DymolaAPI(\n",
    "    # Used for saving simulation files etc.\n",
    "    cwd=os.path.join(os.getcwd(), \"data\"),\n",
    "    # Name of the model you want to simulate\n",
    "    model_name=\"Modelica.Thermal.FluidHeatFlow.Examples.PumpAndValve\",\n",
    "    # All package.mo files required.\n",
    "    # For this MSL model, no further packages are required.\n",
    "    packages=[],\n",
    "    # Whether the Dymola Window should be visible or not\n",
    "    show_window=True,\n",
    "    # Set the output as equidistant (Events are not stored)\n",
    "    equidistant_output=True,\n",
    "    # In some cases MemoryExceptions may occur after some 1000 simulations.\n",
    "    # Restart dymola to free up space.\n",
    "    n_restart=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you have Dymola installed in an unusual path (e.g. on Windows outside of `C:\\Program Files` (and for 64bit-systems `C:\\Program Files (x86)`)) you have to provide the path of your dymola interface and the dymola-executable. Add the following kwargs to the code above to do so:\n",
    "\n",
    "```python\n",
    "dymola_api.DymolaAPI(\n",
    "     # Usual arguments go here...\n",
    "     dymola_path=r\"PATH_TO_DYMOLA\\Dymola 20XX\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a simulation for one minute (60 s) and look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_setup = {\"start_time\": 0,\n",
    "             \"stop_time\": 60}\n",
    "# This simulation setup is equal to the simulation-setup window in Dymola.\n",
    "# Look at the documentation to see what other parameters you may set.\n",
    "DYM_API.set_sim_setup(sim_setup)\n",
    "DYM_API.result_names = [\"ambient1.flowPort.m_flow\"]\n",
    "# Simulate the model. Note that there are different options at hand to get the simulation results. \n",
    "# See the docstring of the class for more information on that.\n",
    "# We will use matfiles for now:\n",
    "df = DYM_API.simulate()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that our simulation is not equal to our measurement. \n",
    "\n",
    "To minimize the error between simulation and measurement, the EBC institute offers the python framework `AixCaliBuHa`. `AixCaliBuHa` offers different calibrators, all based on the `Optimizer` in `ebcpy`. The underlying data-structure is the `data_types` module.  \n",
    "You find **`AixCaliBuHa`** [here](https://github.com/RWTH-EBC/ebcpy/AixCaliBuHA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "As mentioned above, `ebcpy` provides an `Optimizer`. Currently, we use the optimizer primarily for calibration. However, the optimizer is capable of solving other problems as well.\n",
    "\n",
    "We offer an easy to use API for some open-source solvers (`scipy`, `dlib`) as well as own implementation of existings methods (currenlty in development). \n",
    "\n",
    "**Note:** If you have a reoccuring task of optimization with a similar objective function, the use of this framework may make sense for you. If you just optimize once, this won't be much of a help. \n",
    "\n",
    "Let's assume we have some function and we want to approximate a quadratic formula to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generate array between 0 and pi\n",
    "data = np.linspace(0, np.pi, 100)\n",
    "goal = np.sin(data)\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the optimal parameters by creating our own Optimizer. You may want to pass own arguments to the class for usage in the objective. Just overwrite the `__init__` of the `Optimizer`. \n",
    "Depending on your use-case, you may want to pass `x0` and `bounds` as well. Some solvers don't require initial values. Boundaries are mostly required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebcpy.optimization import Optimizer\n",
    "\n",
    "class MyCustomOptimizer(Optimizer):\n",
    "\n",
    "    def __init__(self, goal, data, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.goal = goal\n",
    "        self.data = data\n",
    "\n",
    "    def obj(self, xk, *args):\n",
    "        # Calculate the quadratic formula:\n",
    "        quadratic_func = xk[0] * self.data ** 2\\\n",
    "                            + xk[1] * self.data\\\n",
    "                            + xk[2]\n",
    "        # Return the MAE of the quadratic function.\n",
    "        return np.sum(np.abs(self.goal - quadratic_func))\n",
    "\n",
    "mco = MyCustomOptimizer(goal=goal,\n",
    "                        data=data,\n",
    "                        bounds = [(-100, 100), (-100, 100), (-100, 100)]  # Specify bounds to the optimization\n",
    "                        )\n",
    "\n",
    "res = mco.optimize(framework=\"scipy_differential_evolution\", method=\"best1bin\")\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.plot(data, res.x[0] * data ** 2 + res.x[1] * data + res.x[2], \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the advantage of the optimizer class, see the solutions for different frameworks below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mco.optimize(framework=\"scipy_minimize\",\n",
    "                   method=\"L-BFGS-B\",\n",
    "                   x0=[0, 0, 0]  # L-BFGS-B method requires an initial guess.\n",
    "                  )\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.plot(data, res.x[0] * data ** 2 + res.x[1] * data + res.x[2], \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mco.optimize(framework=\"dlib_minimize\",\n",
    "                   num_function_calls=1000  # Limit number of function calls\n",
    "                   )\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.plot(data, res.x[0] * data ** 2 + res.x[1] * data + res.x[2], \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = mco.optimize(framework=\"pymoo\", method=\"DE\")\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.plot(data, res.x[0] * data ** 2 + res.x[1] * data + res.x[2], \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you have any questions or encounter bugs, please feel free to [raise an issue](https://github.com/RWTH-EBC/ebcpy/issues)! We hope this tutorial made the use case and usage of `ebcpy` clear to you. We also refer to the python examples in the examples folder. Here you can also test the objects within in the framework.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
