{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on ebcpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the following situation.\n",
    "From an experiment we have gathered following data:\n",
    "<img src=\"tutorial/measured_data.png\">\n",
    "We want to use the data as an input to a simulation. However, as visible, the data is noisy and thus may lead to instability of our simulation.\n",
    "\n",
    "First we will load modules supporting this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Types\n",
    "Let's specify the path to our measurement data and load it.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ebcpy import data_types\n",
    "# Specify the path to the measured data:\n",
    "path = os.path.join(os.getcwd(), \"tutorial\", \"measuredData.hdf\")\n",
    "try:\n",
    "    data_types.TimeSeriesData(path)\n",
    "except KeyError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why did we expect the error?** One hdf-file can store multiple tables.\n",
    "In this case, 'other test' was stored as-well.\n",
    "\n",
    "The error shows the options you have, 'other test' or 'test'.\n",
    "Same applies for other file-formats. '.csv' needs the seperator (`sep`),\n",
    "and '.xlsx' the name of the sheet (`sheet_name`) as a keyword-argument.\n",
    "\n",
    "'test' holds in this case the correct data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsd = data_types.TimeSeriesData(path, key=\"test\")\n",
    "print(tsd)\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.title(\"1: Measured data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "If you're familiar with `python` and `DataFrames`, you will ask  yourself: **Why do I need the TimeSeriesData-Class?** We implemented this class to combine the powerful `pandas.DataFrame` class with new functions for an easy usage in the context of Building Energy Systems for three main reasons:\n",
    "- Most data in our case is Time-Dependend, therefore functions for easy conversion between seconds (for Simulation) and Timestamps (for measurements) is needed \n",
    "- Most data is stored in files. Typically .hdf and .mat is used, .csv and even .xlsx files occur frequently. Pandas has different functions (`from_hdf`, `from_csv`) and no at all function for loading Modelica-Result files.\n",
    "- Working with energy related data, you most likely are interested in understanding where a value comes from. For this reason we base the TimeSeriesData-Class on the pandas MultiColumn-Feature. Every variable (e.g. Temperature) will get tags for specific reasons. The default being \"raw\", assuming that data loaded from a file without tags most likely is unprocessed.\n",
    "\n",
    "Note how the loaded measurement got the tag 'raw'. Else not much new, just DataFrame. Let's adjust the noisy data for the usage in a simulation tool like Modelica.\n",
    "\n",
    "For this reason, we load the preprocessing module of `ebcpy`. \n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "We want to manipulate only the values in the DataFrame. Therefore we need to first extract the data. We use numpy as a return type, as most preprocessing functions like filters run on numpy-arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ebcpy import preprocessing\n",
    "# Extract the column of interest to get the trajectory or array for processing\n",
    "trajectory = tsd.get_columns_by_tag(\"raw\", columns=[\"measured_T\"], return_type=\"numpy\")\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then can apply either a filter or a moving-average. To further understand differences between both options, adjust the parameters in the box below and rerun the cell. You will see how the output changes. Which function you use for your data is up to you, a general appraisal cannot be made.\n",
    "\n",
    "**Note**: The syntax for values for an existing variable with a new tag, you have to call:\n",
    "```python\n",
    "tsd[VARIABLE_NAME, NEW_TAG_NAME] = VALUES\n",
    "```\n",
    "In this case: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tsd[\"measured_T\", \"low_pass_filter\"] = preprocessing.low_pass_filter(data=trajectory, \n",
    "                                                                     crit_freq=0.01, \n",
    "                                                                     filter_order=2)\n",
    "tsd[\"measured_T\", \"moving_average\"] = preprocessing.moving_average(data=trajectory, \n",
    "                                                                   window=10)\n",
    "# Plot the values\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.legend(tsd[\"measured_T\"].columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's assume we want to know when to turn on a certain device based on our measurements. Looking at our data, we know some device turned on or off, if the temperature rises above some 34 Â°C. To reproduce the signal for our simulation, we can use the `create_on_off_signal` method. For this example we use the default tag \"raw\", however you may also try \"moving_average\" or other created tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "tsd = preprocessing.create_on_off_signal(df=tsd,\n",
    "                                         col_names=[\"measured_T\"],\n",
    "                                         threshold= 307,\n",
    "                                         col_names_new=[\"Device_Input\"],\n",
    "                                         tags=[\"raw\"],\n",
    "                                         new_tag=\"converted_signal\")\n",
    "plt.plot(tsd[\"Device_Input\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are satisfied with our results, we may want to save our process in a file. For this case, the `TimeSeriesData`-Class holds a `save`-function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(os.getcwd(), \"tutorial\", \"measuredData_preprocessed.hdf\")\n",
    "tsd.save(save_path, key=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data again and check if everything was correctly saved and the load-function also works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()\n",
    "tsd = data_types.TimeSeriesData(save_path, key=\"test\")\n",
    "plt.plot(tsd[\"measured_T\"])\n",
    "plt.legend(tsd[\"measured_T\"].columns.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a closer look at the DataFrame-Object.\n",
    "\n",
    "We now have two variables, the measured temperature and the created signal. Furthermore we created new tags, allowing us to always recap where our data came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, the measurement was made for 1 hour with a 1 second interval. Let's assume you want to run the simulation with a bigger time-interval. To not only use the data, but at a later stage also compare results, the `preprocessing` module holds a function for you.\n",
    "`clean_and_space_equally_time_series` Takes your data and resamples it to the desired frequency. Try different inputs, like \"1s\", \"30s\", \"2min\", \"1h\" or others.\n",
    "\n",
    "- Be aware that **upsampling** your data is to create artificial values. In contrast, **downsampling** is a valid and secure method.\n",
    "- See [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#timeseries-offset-aliases) for allowed frequencies like \"15min\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.clean_and_space_equally_time_series(tsd, desired_freq=\"1min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion\n",
    "\n",
    "Now let's get to the simulation part. If you are familiar with **Modelica**, you know *inputs from files* may either be in `.txt` or `.mat` format. Both options are supported in `ebcpy`.\n",
    "\n",
    "Let's take our preprocessed data and convert it to first to .txt, then to .mat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebcpy.utils import conversion\n",
    "\n",
    "file_path = os.path.join(os.getcwd(), \"tutorial\", \"measuredData_preprocessed.hdf\")\n",
    "\n",
    "success, save_path_txt = conversion.convert_hdf_to_modelica_txt(filepath=file_path,\n",
    "                                                                table_name=\"Simulation_Input\",\n",
    "                                                                # Lets use the default save-path\n",
    "                                                                save_path_file=None,  \n",
    "                                                                # = [], = [(\"measured_T\", \"moving_average\")] o.s. is also possible.\n",
    "                                                                columns=[\"Device_Input\"],\n",
    "                                                                key=\"test\",\n",
    "                                                                # Rerun the cell and change values \n",
    "                                                                # below to understand these args.\n",
    "                                                                offset=0, \n",
    "                                                                sep=\"\\t\")\n",
    "\n",
    "# Let's print the first 15 lines to understand the result. \n",
    "# Simulation_Input is the table_name. \n",
    "# The tag is added to the varialbe\n",
    "print(\"\".join(open(save_path_txt, \"r\").readlines()[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion.convert_hdf_to_modelica_mat(filepath=file_path,\n",
    "                                       save_path_file=None,\n",
    "                                       columns=[(\"measured_T\", \"moving_average\")],\n",
    "                                       key=\"test\",\n",
    "                                       offset=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dymola API\n",
    "\n",
    "Now we will run a simulation using the `DymolaAPI`-Class. Make sure you have **Dymola** with a valid **license** installed on your machine to get this to run.\n",
    "\n",
    "If you are new to the research at the EBC-Institute, the [**AixLib**](https://github.com/RWTH-EBC/AixLib) is a good  starting point for modelling. Most systems with regard to building energy systems have been already implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebcpy.simulationapi import dymola_api\n",
    "test_package = os.path.join(os.getcwd(), \"Modelica\", \"AixCalTest\", \"package.mo\")\n",
    "\n",
    "DYM_API = dymola_api.DymolaAPI(\n",
    "                        # Used for saving simulation files etc.\n",
    "                        cd=os.path.join(os.getcwd(), \"data\"),\n",
    "                        # Name of the model you want to simulate\n",
    "                        model_name=\"AixCalTest.TestModelInput\",\n",
    "                        # All package.mo files required\n",
    "                        packages=[test_package],\n",
    "                        # Whether the Dymola Window should be visible or not\n",
    "                        show_window=True,\n",
    "                        # Append structural parameters as modifiers to the\n",
    "                        # Simulation\n",
    "                        get_structural_parameters=True,\n",
    "                        # Set the output as equidistant (Events are not stored)\n",
    "                        equidistant_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you have Dymola installed in an unusual path (e.g. on Windows outside of `C:\\Program Files` (and for 64bit-systems `C:\\Program Files (x86)`)) you have to provide the path of your dymola interface and the dymola-executable. Add the following kwargs to the code above to do so:\n",
    "\n",
    "```python\n",
    "dymola_api.DymolaAPI(\n",
    "     cd=os.path.join(os.getcwd(), \"data\"),\n",
    "     model_name=\"AixCalTest.TestModelInput\",\n",
    "     packages=[test_package],\n",
    "     show_window=True,\n",
    "     get_structural_parameters=True,\n",
    "     equidistant_output=True,\n",
    "     dymola_interface_path=r\"PATH_TO_DYMOLA\\Dymola 20XX\\Modelica\\Library\\python_interface\\dymola.egg\",\n",
    "     dymola_path=r\"PATH_TO_DYMOLA\\Dymola 20XX\\bin64\\Dymola.exe\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running our simulation, we have to understand the underlying model. \n",
    "\n",
    "<img src=\"tutorial\\TestModelInput.png\">\n",
    "\n",
    "We have a simple Heat-Exchanger between two heaters. The heaters are basically pipes. For each pipe, a source set's the temperature and mass flow rate. The latter is provided as a constant parameter, either 0 or some fixed value, depending on a input signal. The signal turns the mass flow rate off if the value is greater than 0, representing an easy on-off control. To simulate our data, we have to add our input data to the `CombiTimeTable` so that Modelica knows where the input comes from. \n",
    "\n",
    "We double click the `CombiTimeTable` instance and the parameter window appears. Here, we set our file name (from the conversion) and the table name in the file (\"Simulation_Input\") in our case. As we converted only our Device_Input signal to `.txt`, we have to access it using the second column, therefore \"{2}\". {1} is always the Time.\n",
    "\n",
    "<img src=\"tutorial\\CombiTimeTableInput.png\">\n",
    "\n",
    "In our tutorial, we still need to copy our device input to the location Modelica will search for the file, in this case in the \"\\Input\" folder of the `AixCalTest` package. **NOTE:** In future versions, this manual copy will be replaced by a model wrapper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy our input data into the Modelica-Input folder:\n",
    "from shutil import copyfile\n",
    "modelica_input_folder = os.path.join(os.getcwd(), \"Modelica\", \"AixCalTest\", \"Input\", \"model_input.txt\")\n",
    "copyfile(save_path_txt, modelica_input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand our model, we can simulate it. You can run this single simulation either through the API or directly in Dymola. The API is only handy for when you need to run lot's of simulations with different parameters (Calibration, Optimization).\n",
    "\n",
    "When running the simulatiion with the `DymolaAPI` instance `DYM_API` a Dymola process is started (eventually just as a background process).\n",
    "\n",
    "Let's run a simulation for one hour (3600 s) and look at the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_setup = {\"startTime\": 0,\n",
    "             \"stopTime\": 3600}\n",
    "# This simulation setup is equal to the simulation-setup window in Dymola.\n",
    "# Look at the documentation to see what other parameters you may set.\n",
    "DYM_API.set_sim_setup(sim_setup)\n",
    "\n",
    "# Simulate the model. Note that there are different options at hand to get the simulation results. \n",
    "# See the docstring of the class for more information on that.\n",
    "# We will use matfiles for now:\n",
    "file_path_result = DYM_API.simulate(savepath_files=\"my_result.mat\")\n",
    "\n",
    "# Load the DataFrame and plot our variable of interest, in this case the pipe-Temperature.\n",
    "tsd_sim = data_types.TimeSeriesData(file_path_result)\n",
    "plt.plot(tsd_sim[\"heater1.heatPorts[1].T\"].values, \"r\")\n",
    "plt.plot(tsd[(\"measured_T\", \"moving_average\")].values, \"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that our simulation is not equal to our measurement. \n",
    "\n",
    "To minimize the error between simulation and measurement, the EBC institute offers the python framework `AixCaliBuHa`. `AixCaliBuHa` offers different calibrators, all based on the `Optimizer` in `ebcpy`. The underlying data-structure is the `data_types` module.  \n",
    "You find **`AixCaliBuHa`** [here](https://git.rwth-aachen.de/EBC/EBC_all/Optimization-and-Calibration/AixCaliBuHA)\n",
    "\n",
    "To analyze `TimeSeriesData` and cluster or classify it, we refer to `EnStATS`, a library desgined to use Statistics and Machine Learning to analyze energy data.  \n",
    "You find **`EnStATS`** [here](https://git.rwth-aachen.de/EBC/EBC_all/Optimization-and-Calibration/enstats)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "As mentioned above, `ebcpy` provides an `Optimizer`. Primarily used for calibration. However, the optimizer is capable of solving other problems as well.\n",
    "\n",
    "We offer an easy to use API for some open-source solvers (`scipy`, `dlib`) as well as own implementation of existings methods (to be done). \n",
    "\n",
    "**Note:** If you have a reoccuring task of optimization with a similar objective function, the use of this framework may make sense for you. If you just optimize once, this won't be much of a help. \n",
    "\n",
    "Let's assume we have some function and we want to approximate a quadratic formula to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Generate array between 0 and pi\n",
    "data = np.linspace(0, np.pi, 100)\n",
    "goal = np.sin(data)\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the optimal parameters by creating our own Optimizer. You may want to pass own arguments to the class for usage in the objective. Just overwrite the `__init__` of the `Optimizer`. \n",
    "Depending on your use-case, you may want to pass `x0` and `bounds` as well. Some solvers don't require initial values. Boundaries are mostly required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ebcpy.optimization import Optimizer\n",
    "\n",
    "class MyCustomOptimizer(Optimizer):\n",
    "\n",
    "    # Our initial guesses (only scipy-minimize needs this)\n",
    "    x0 = np.array([0, 0, 0])\n",
    "    # Boundaries to our parameters.\n",
    "    bounds = [(-100, 100), (-100, 100), (-100, 100)]\n",
    "\n",
    "    def __init__(self, cd, goal, data, **kwargs):\n",
    "        self.goal = goal\n",
    "        self.data = data\n",
    "        super().__init__(cd, **kwargs)\n",
    "\n",
    "    def obj(self, xk, *args):\n",
    "        # Calculate the quadratic formula:\n",
    "        quadratic_func = xk[0] * self.data ** 2\\\n",
    "                            + xk[1] * self.data\\\n",
    "                            + xk[2]\n",
    "        # Return the MAE of the quadratic function.\n",
    "        return np.sum(np.abs(self.goal - quadratic_func))\n",
    "\n",
    "mco = MyCustomOptimizer(cd=os.getcwd(),  # Used for the logger, we dont use this in this tutorial.\n",
    "                        goal=goal,\n",
    "                        data=data)\n",
    "\n",
    "res = mco.optimize(framework=\"scipy_differential_evolution\", method=\"best1bin\")\n",
    "plt.plot(data, goal, \"r\")\n",
    "plt.plot(data, res.x[0] * data ** 2 + res.x[1] * data + res.x[2], \"b.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you have any questions or encounter bugs, please feel free to [raise an issue](https://git.rwth-aachen.de/EBC/EBC_all/Python/ebcpy/issues)! We hope this tutorial made the use case and usage of `ebcpy` clear to you. We also refer to the python examples in the examples folder. Here you can also test the objects within in the framework.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
